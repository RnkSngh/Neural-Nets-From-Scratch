{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-091d17bcaf7f>, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-091d17bcaf7f>\"\u001b[1;36m, line \u001b[1;32m55\u001b[0m\n\u001b[1;33m    for output_neuron in self.get_layer(-1):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Neural Net from Scratch; uses a relu function\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "def relu(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#deravitive of relu function\n",
    "def relu_der(x):\n",
    "    if x<=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "class Neural_Net:\n",
    "    def __init__(self):\n",
    "        self.nodes = [] #list of list of lists where the first index is the layer and second is node in that layer\n",
    "        self.graph = nx.Graph()\n",
    "        self.training_inputs = [] #matrix of training inputs\n",
    "        self.training_outputs = [] # matrix of training outputs\n",
    "        self.connections = []\n",
    "        self.num_links = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "    \n",
    "    def add_neuron(self, layer, new_neuron): #adds a new neuron at layer (index starting from 0)\n",
    "        self.nodes.append(new_neuron)\n",
    "        self.graph.add_node(new_neuron)\n",
    "    \n",
    "    def add_connectivity(self, left_neuron, right_neuron, weight=1): #connectivity between left and right neurons\n",
    "        new_connection = connection(left_neuron, right_neuron, weight)\n",
    "        left_neuron.right_connections.append(new_connection)\n",
    "        right_neuron.left_connections.append(new_connection)\n",
    "        self.connections.append(new_connection)\n",
    "        #add graph for displaying network\n",
    "        self.graph.add_edge(left_neuron, right_neuron, weight)\n",
    "    \n",
    "    #gets the neuron at self, layer, and index\n",
    "    def get_neuron(self, layer, index): \n",
    "        return self.nodes[layer][index]\n",
    "    \n",
    "    #return an array of neurons in a given layer, where layer is a python index\n",
    "    def get_layer(self, layer):\n",
    "        return self.nodes[layer]\n",
    "\n",
    "    def plot_net(self):\n",
    "        nx.draw(self.graph, with_labels=True)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    #update the gradient for a single training example. \n",
    "    def calculate_gradient(self, training_input, training_output): #cost function to update gradients. Gradient\n",
    "        #apply training input\n",
    "        self.calculate(training_input)\n",
    "        \n",
    "        #iterate backwards through layers and update gradients\n",
    "        for layer in reversed(self.nodes):\n",
    "            for node in layer:\n",
    "                node.calculate_gradient_term()\n",
    "                for node_connection in node.left_connections:\n",
    "                    node_connection.calculate_gradient_term()\n",
    "        return\n",
    "                \n",
    "    def calculate(self, input_vector): #applies weights and biases throughout the neural net for a given input\n",
    "        for node_index, node in self.nodes:  #update input nodes\n",
    "            node.compute(input_vector[node_index])\n",
    "        for layer in self.nodes[1:]: #update the rest of the nodes\n",
    "            for node in layer:\n",
    "                node.compute()\n",
    "    \n",
    "    #applies the gardient descent from calculated gradients\n",
    "    def subtract_gradient(self, alpha):\n",
    "        #iterate through nodes and update the nodes\n",
    "        for layer in self.nodes:\n",
    "            for node in layer:\n",
    "                node.gradient_term = mean(node.gradient_set)\n",
    "                node.bias -= alpha*node.gradient_term\n",
    "                node.gradient_set = []\n",
    "                \n",
    "        for connection in self.connections:\n",
    "            connection.gradient_term = mean(connection.gradient_set)\n",
    "            connection.weight -= alpha*connection.gradient_term\n",
    "            connection.gradient_set = []\n",
    "                \n",
    "        return\n",
    "\n",
    "    #trains a neural net for given inputs and outputs\n",
    "    #each training set is assumed to be a row of numpy array n iterations to meet \n",
    "    def train(self, training_inputs, training_outputs, iterations):\n",
    "        for i in xrange(iterations):\n",
    "            \n",
    "            for index, training_input in training_inputs:\n",
    "                training_output = training_outputs[index]\n",
    "                self.calculate_gradient(training_input, training_output)\n",
    "\n",
    "            self.subtract_gradient(.01)\n",
    "    #def predict(self, training_data):\n",
    "        \n",
    "class Neuron: \n",
    "    def __init__(self):\n",
    "        self.bias = 0\n",
    "        self.activation= 1\n",
    "        self.left_connections = [] #all connections to neurons to the left\n",
    "        self.right_connections = [] #all connections to neurons to the right\n",
    "        self.z = 1 #last value before applying the activation function; used for derivatives\n",
    "        self.gradient_term = 0 #list of terms for each gradient term, corresponding to a training example\n",
    "        self.gradient_set = [] #set of gradients already calculated in the training set\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.activation)\n",
    "    \n",
    "    #compute output of neuron using bias and weight\n",
    "    def compute(self):\n",
    "        left_sum = 0 #increment sum\n",
    "        #sum up all contributions from left nodes\n",
    "        for left_connection in self.left_connections:\n",
    "            left_node = left_connection.left_neuron\n",
    "            weight = left_connection.weight\n",
    "            left_sum += left_node.activation*weight + left_node.bias \n",
    "        \n",
    "        #z is the input before, used for calcualating the deravitive of activation function\n",
    "        self.z = left_sum\n",
    "        #apply activation function\n",
    "        self.activation = relu(left_sum)\n",
    "    \n",
    "    #calculate gradient term for the bias associated with the node\n",
    "    def calculate_gradient_term(self):\n",
    "        grad_term = 0\n",
    "        if self is Output_Neuron:\n",
    "            self.gradient_term = 2*( self.activation - self.training_value)\n",
    "        else:\n",
    "            for right_connection in self.right_connections:\n",
    "                grad_term += right_connection.gradient_term/self.activation #get rid of the self.activation because you diffirientate it away\n",
    "            sigma_prime = relu_der(self.z)\n",
    "            self.gradient_term = grad_term* sigma_prime\n",
    "            \n",
    "        self.gradient_set.append(self.gradient_term)\n",
    "        \n",
    "class OutputNeuron(Neuron):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training_value = 0\n",
    "\n",
    "class InputNeuron(Neuron):\n",
    "    def __init__(self):\n",
    "        super().__init()\n",
    "        self.activation = 1\n",
    "    \n",
    "    def compute(self, training_input):\n",
    "        self.z = training_input\n",
    "        self.activation = relu(training_input)\n",
    "\n",
    "class connection: \n",
    "    def __init__(self, left_neuron, right_neuron, weight):\n",
    "        self.left_neuron = left_neuron\n",
    "        self.right_neuron = right_neuron\n",
    "        self.weight = weight\n",
    "        self.gradient_term = 0 #term currently being updated\n",
    "        self.gradient_set = [] #set of gradients already calculated in the training set\n",
    "    \n",
    "    def calculate_gradient_term(self):\n",
    "        right_node = self.right_neuron\n",
    "        left_node = self.left_neuron\n",
    "        if right_node is OutputNeuron:#means we are at the root node\n",
    "            sigma_prime = relu_prime(right_node.z)\n",
    "            grad_term = left_node.activation*sigma_prime*2(right_node.activation-right_node.training_value)\n",
    "            self.gradient_term = grad_term\n",
    "        else: \n",
    "            grad_term = 0\n",
    "            sigma_prime = relu_prime(right_node.z)\n",
    "            for right_nodes in right_node.right_connections:\n",
    "                grad_term += right_node.gradient_term*right_node.weight/right_node.activation\n",
    "            self.gradient_term = grad_term*left_node.activation*sigma_prime \n",
    "        \n",
    "        self.gradient_set.append(self.gradient_term)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_net = Neural_Net()\n",
    "u = Neuron()\n",
    "\n",
    "v = Neuron()\n",
    "w= Neuron()\n",
    "main_net.add_neuron(1, u)\n",
    "main_net.add_neuron(2, v)\n",
    "main_net.add_connectivity(u,v)\n",
    "main_net.add_neuron(3,w)\n",
    "main_net.add_connectivity(v, w)\n",
    "v.bias=2\n",
    "v.compute()\n",
    "main_net.plot_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 1]\n",
      "1 [2 3]\n",
      "2 [4 5]\n",
      "3 [6 7]\n",
      "4 [8 9]\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(10).reshape(5,2)\n",
    "for row, index in enumerate(a):\n",
    "    print (row, index)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
